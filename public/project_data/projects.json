{
  "defaults": {
    "rowStart": "row-auto",
    "colStart": "col-auto",
    "rowSpan": "row-span-1",
    "colSpan": "col-span-1",
    "smRowSpan": "sm:row-span-1",
    "smColSpan": "sm:col-span-1",
    "mdRowSpan": "md:row-span-1",
    "mdColSpan": "md:col-span-1",
    "smRowStart": "sm:row-auto",
    "smColStart": "sm:col-auto",
    "mdRowStart": "md:row-auto",
    "mdColStart": "md:col-auto"
  },
  "projects": [
    {
      "id": "gaussian-glasses",
      "name": "Gaussian Glasses",
      "image_path": "stylized/gg_logo.png",
      "ss_path": "gg_ss.png",
      "date": "2025",
      "description": "Making camouflaged images classifier-legible through RL-optimized diffusion",
      "tags": [],
      "status": "sunset",
      "role": "Dev",
      "overview": [
        "Research exploring: 'can a diffusion model restore discriminative structure in ambiguous or corrupted inputs?' We test this question on a dataset of camouflaged animals, seeing if the generative model can enhance the picture of the hidden animal.",

        "TLDR: the results were largely unsuccessful. The task effectively transfers the burden of discrimination onto a generative model — a role in which it is inherently less capable than a purpose-built discriminative model.",

        "Read the [blog](https://hectorastrom.github.io/gaussian-glasses/), or use the [ImageDDPO package](https://pypi.org/project/imageddpo/0.1.2/) for your own experiments."
      ],
      "team": [
        { "Kevin Zhu": "" },
        { "Luc Gaitskell": "" }
      ],
      "note": "Developed as part of my final project for 6.7960 in fall 2025.",
      "website": "https://hectorastrom.github.io/gaussian-glasses/"
    },
    {
      "id": "trinket",
      "image_path": "stylized/trinket_logo.png",
      "name": "Trinket",
      "date": "2025",
      "description": "Transform any photo into a 3D collectible.",
      "tags": [],
      "status": "ongoing",
      "role": "Dev",
      "overview": [
        "[trinket.world](https://trinket.world) makes it effortless to capture and share digital memorabilia with friends. In one click, Trinket transforms a 2D image into a permanent, 3D collectible that can be shared with friends instantaneously.",

        "Behind the scenes, each photo flows through a three-step pipeline: it’s uploaded to our Next.JS servers, stylized with a custom Nano Banana prompt through the Gemini API, then passed to a self-hosted mesh diffusion model (Hunyuan 3D 2.0) to generate a vivid 3D trinket -- all in under 30 seconds. Trinkets are stored as two images (original, nano render) and models (.glb files) in Supabase buckets. The frontend is hosted through Vercel.",

        "Try it! (while I still have Supabase credits)"
      ],
      "team": [
        { "Albert Astrom": "Dev" },
        { "Christina Li": "Dev" },
        { "Ryan Qiu": "Dev" }
      ],
      "note": "Trinket was developed as part of HackMIT 2025, MIT's 24 hour hackathon.",
      "website": "https://trinket.world",
      "ss_path": "trinket_ss.png"
    },
    {
      "id": "lucid",
      "image_path": "stylized/lucid_logo.png",
      "name": "Lucid Labs",
      "date": "2025",
      "description": "The first continuous brain wearable: built to optimize your cognitive & physical health.",
      "tags": [],
      "status": "former",
      "role": "Cofounder",
      "overview": [
        "Lucid is the always-on wearable for your brain, decoding neural activity to unlock peak cognitive health and performance.",

        "The brain is our most volatile asset, yet it’s the only organ without proactive monitoring. Consumers track heart, sleep, and glucose with wearables, but remain blind to cognition. Without a feedback loop, workers waste focus, patients miss early warning signs, and society bears the rising cost of dementia.",

        "Lucid turns bulky EEG headsets into a discreet, continuously wearable device. Our hyperfocus on developing brain foundation models (BFMs) enable us to classify focus, stress, and recovery with unprecedented accuracy, offering real-time cognitive insights. These everyday benefits are the first step toward our larger mission: a preventative health platform for detecting neurodegeneration, epilepsy, and cognitive decline."
      ],
      "team": [{ "Ryan Yue": "Cofounder" }, { "Trevor Xing-Xie": "Cofounder" }]
    },
    {
      "id": "geompt",
      "image_path": "stylized/geompt_logo.png",
      "ss_path": "geompt169_ss.png",
      "gif_path": "geompt_gif.gif",
      "name": "GeomPT",
      "date": "2024",
      "description": "AI-powered physical therapy platform to improve patient recovery outcomes through data-driven insights.",
      "tags": ["OpenCV", "MediaPipe", "Flask", "Firebase", "Next.js", "React"],
      "status": "sunset",
      "github": "https://github.com/orgs/GeomPT/repositories",
      "website": "https://drive.google.com/file/d/1R7GtYhcAP-BwZhLpbZXQBIYWqDoNPzsP/view?usp=sharing",
      "hackathon_page": "https://ballot.hackmit.org/project/fnjby-pztke-ionsy-qebtg",
      "role": "Technical Lead",
      "overview": [
        "GeomPT is an AI-powered web platform for physical therapy providers to track and analyze patients' range of motion (ROM) over time, addressing patient non-adherence and improving rehabilitation outcomes through data-driven insights and enhanced plan-of-care adherence. The platform is designed to assist rather than replace professional physical therapists, supporting both the patient and provider throughout a prescribed program.",
        "GeomPT organizes patient recovery plans, compiling all prescribed exercises in one place with video and text instructions, along with prescribed sets and reps for easy reference.",
        "The platform leverages OpenCV and Mediapipe's Pose Model to automatically measure and track key joint angles during physical therapy exercises. By analyzing video data sent across websockets in real time, GeomPT provides clinicians and patients with granular recovery insights.",
        "All patient progress and exercise data are securely stored in Firebase, allowing providers to review, monitor, and adjust treatment plans based on objective ROM metrics and patient performance trends. LLM data analysis provides 'at-a-glance' insights into patient health and recovery progress."
      ],
      "note": "GeomPT was developed as part of HackMIT 2024, MIT's 24 hour hackathon. It earned second place overall out of 200+ teams.",
      "team": [
        { "Allen Liu": "Fullstack Dev" },
        { "Steven Zhang": "Frontend Dev" },
        { "Sandro Gopal": "Backend Dev" }
      ]
    },
    {
      "id": "cri",
      "image_path": "stylized/cri_logo.png",
      "ss_path": "cri169_ss.png",
      "gif_path": "cri_gif.gif",
      "name": "CRInteractive",
      "date": "2021 - 2023",
      "description": "Platform to quantify and track rowing performance metrics.",
      "tags": ["Python", "Flask", "SQLite", "Bootstrap"],
      "status": "sunset",
      "github": "https://github.com/hectorastrom/CRInteractive",
      "website": "https://www.crinteractive.org/",
      "role": "Software Engineer",
      "overview": [
        "At its core, CRInteractive was designed to quantify, track, and visualize key rowing performance metrics. This transparency in data allowed athletes to focus on specific practice goals and understand their areas of improvement.",
        "Coaches benefited from an intuitive platform to discuss team strategies and individual performance, fostering an environment of open communication and shared team objectives.",
        "At its peak, the app had over 100 active users and managed thousands of database entries, making it a pivotal tool in rowing team management and support."
      ],
      "team": [{ "Albert Astrom": "Software Engineer" }]
    },
    
    {
      "id": "metatour",
      "image_path": "stylized/metatour_logo.png",
      "ss_path": "metatour_ss.png",
      "gif_path": "metatour_gif.gif",
      "name": "Meta Tour",
      "date": "2022",
      "description": "Google Street View-like platform tailored for home tours.",
      "tags": ["Swift", "OpenCV", "IMUFusion", "Flask"],
      "status": "sunset",
      "github": "https://github.com/womogenes/meta-tour",
      "role": "Backend Developer",
      "overview": [
        "Meta Tour featured a Swift app that utilized iPhone telemetry data to enable users to create 3D maps of their homes.",
        "Users could enhance their tours by adding 3D panoramas at points of interest throughout their mapped homes.",
        "These tours were shareable online and could be accessed via a Flask-based web application."
      ],
      "note": "Meta Tour was developed as a final project for a seven-week computer vision course at Harvard.",
      "team": [{ "William Feng et. al": "Fullstack" }]
    }
  ]
}
